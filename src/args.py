import argparse
import os
import json 

PARSER = argparse.ArgumentParser(description='Run given network on the given split and store outpus + running times')

PARSER.add_argument('file', default='splits.json')
PARSER.add_argument('datasets_dir', help="directory containing root folders of each dataset")
PARSER.add_argument('--resume','-r', default=None)
PARSER.add_argument('--resume_method', '-rs', default=None)
PARSER.add_argument('--outdir','-o', default=os.path.join('..','predictions'))
PARSER.add_argument('--dataset','-d', default='kitti2015')
PARSER.add_argument('--datasetsplit','-ds', default='training')
PARSER.add_argument('--splitname', '-s', default='validation1')
PARSER.add_argument('--method', '-m', default='LEAStereo')
PARSER.add_argument('--permute_keys', '-sk',nargs="+",default=[], help="permute the given keys from the dataset (inputs), for calculating feature importance")
PARSER.add_argument('--local_rank', '-loc_r',type=int,default=-1 ,help="the uniue id of the process (0 = master), decides which GPU is used")
PARSER.add_argument('--replace_keys', '-rk',type=json.loads)
PARSER.add_argument('--save_name', '-sn',default=None)

PARSER_TRAIN = argparse.ArgumentParser(description='Run given network on the given split and store outpus + running times')
PARSER_TRAIN.add_argument('file')
PARSER_TRAIN.add_argument('datasets_dir', help="directory containing root folders of each dataset")
PARSER_TRAIN.add_argument('save', help="path to overwrite/save new weights to")
PARSER_TRAIN.add_argument('valsplit',help="hold out split name")
PARSER_TRAIN.add_argument('trainsplits',nargs="+", help="split names to be used for training")
PARSER_TRAIN.add_argument('--resume','-r', help="path to weights dir to resume from (None)")
PARSER_TRAIN.add_argument('--dataset','-d', default='kitti2015')
PARSER_TRAIN.add_argument('--method', '-m', default='LEAStereo')
PARSER_TRAIN.add_argument('--resume_method', '-rs', default="LEAStereo")
PARSER_TRAIN.add_argument('--epochs', '-e', default=800, type=int)
PARSER_TRAIN.add_argument('--batch', '-b', default=1, type=int)
PARSER_TRAIN.add_argument('--learning_rate', '-lr', default=1e-3, type=float)
PARSER_TRAIN.add_argument('--finetuning_resume', '-fr', default=True, action="store_false" ,help="if true, optimizer and scheduler are not loaded from checkpoint (True)")
PARSER_TRAIN.add_argument('--freeze-starting-with', '-f', default=None ,help="freeze submodules who start with this string (None)")
PARSER_TRAIN.add_argument('--crop_width', '-cw', default=336 ,help="the size of the random crop applied to the input image during training")
PARSER_TRAIN.add_argument('--crop_height', '-ch', default=168 ,help="the size of the random crop applied to the input image during training")
PARSER_TRAIN.add_argument('--local_rank', '-loc_r',type=int,default=-1 ,help="the uniue id of the process (0 = master), decides which GPU is used")
PARSER_TRAIN.add_argument('--permute_keys', '-sk',nargs="+",default=[], help="permute the given keys from the dataset (inputs), for calculating feature importance")
PARSER_TRAIN.add_argument('--replace_keys', '-rk',type=json.loads)
PARSER_TRAIN.add_argument('--seed', '-s',type=int,default=0)
